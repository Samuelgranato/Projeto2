{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@YMartins123***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Samsung'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-910742af87dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Embaralhando as mensagens para reduzir um possível viés\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'shuffle' is not defined"
     ]
    }
   ],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Limpando as mensagens \n",
    "\n",
    "import string\n",
    "import random\n",
    "data=pd.read_excel(\"Samsung.xlsx\")\n",
    "datatest=pd.read_excel(\"Samsung.xlsx\",sheetname=\"Teste\")\n",
    "\n",
    "def sempontuacao(text):  #função que retira todos os sinais(emocotions continuam)\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    return text\n",
    "\n",
    "data[\"Treinamento\"] = data['Treinamento'].apply(sempontuacao)\n",
    "datatest[\"Teste\"] = datatest[\"Teste\"].apply(sempontuacao)\n",
    "data.Treinamento=data.Treinamento.str.replace(\"  \",\" \")#retirando espaços vazios\n",
    "datatest[\"Teste\"] = datatest.Teste.str.replace(\"  \",\" \")\n",
    "data.Treinamento=data.Treinamento.str.replace(\"\\n\",\" \")#retirando espaços vazios\n",
    "datatest[\"Teste\"] = datatest.Teste.str.replace(\"\\n\",\" \")\n",
    "\n",
    "\n",
    "lista_rel = []\n",
    "lista_nrel = []\n",
    "lista_total = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(data[\"Treinamento\"])):\n",
    "    if data[\"Relevancia\"][i]==\"Relevante\":\n",
    "        lista_rel+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "        lista_total+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "    else:\n",
    "        lista_nrel+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "        lista_total+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "        \n",
    "        \n",
    "#lista_rel=  list(set(lista_rel))\n",
    "#lista_nrel = list(set(lista_nrel))\n",
    "\n",
    "lista_total=list(set(lista_total))\n",
    "\n",
    "n_rel = len(lista_rel)\n",
    "n_nrel= len(lista_nrel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.49918133319608e-22, 1.5298526399752945e-20, 1.3796082531454214e-53, 1.064632612905422e-27, 8.150822739403942e-76, 2.1459199292087946e-28, 7.884805603334492e-50, 1.0044487030140821e-23, 2.932873489204252e-57, 1.1253692759517946e-82, 5.93117172960923e-39, 9.977251814051758e-62, 1.0810115761808905e-24, 2.3253760127624476e-18, 1.4400165080704554e-30, 1.6128011461366006e-56, 3.2518969000753134e-59, 4.099099698288363e-68, 1.1556872212887415e-48, 4.823484280590693e-99, 3.1489466839491476e-18, 1.093845113980668e-36, 1.5382196915353148e-39, 3.319144758749126e-51, 1.9301808573783873e-31, 9.911623043691633e-46, 3.0100752736544507e-48, 3.336455482039784e-27, 2.1768957038102116e-34, 2.575965990609379e-41, 5.578617518161701e-54, 3.4154019217242904e-60, 2.871343424199253e-36, 7.448005292922494e-52, 2.890139653876789e-48, 6.506088189977577e-26, 6.621622589542744e-72, 1.390436188113017e-47, 5.93117172960923e-39, 1.2773385077401881e-46, 3.5863620053377343e-75, 1.8307257299122474e-66, 1.3796082531454214e-53, 8.990869509496679e-25, 2.514314537900794e-30, 7.29101800127606e-71, 8.482316333794902e-76, 1.2904945189495734e-65, 7.347542262548012e-19, 4.342194067826313e-75, 5.2849454835510174e-21, 1.0577526439492986e-70, 1.3553028692046554e-71, 1.266781991147294e-52, 1.8543668363336902e-23, 5.514802449652535e-33, 6.026692218084493e-22, 1.674667829462139e-41, 2.154528444322473e-45, 2.5433800139589272e-18, 2.6557458873049354e-49, 4.204661861293482e-25, 3.515241829014532e-50, 3.5327533585500053e-41, 4.661271792531257e-41, 2.0398035199670594e-19, 1.3009929245501913e-45, 4.87178297617377e-81, 3.5681842957289876e-45, 3.0336108263332355e-73, 7.169243184548295e-32, 3.7686382442615216e-37, 2.0564552555589915e-60, 8.341138705099457e-30, 1.3088739253121965e-17, 4.8238029800339905e-37, 2.6091761687560757e-73, 4.2986193952924505e-38, 7.61418747309981e-35, 2.2135138370757172e-69, 3.503557049801659e-46, 2.1551267467721097e-30, 2.081957630078667e-63, 1.3796082531454214e-53, 2.0893105756769607e-56, 7.454165780625605e-71, 5.93117172960923e-39, 2.754770552151073e-57]\n",
      "2.5076413249652066e-19\n",
      "Porcentagem de positivos verdadeiros :11.00%\n",
      "Porcentagem de negativos verdadeiros: 50.00%\n",
      "Porcentagem de positivos falsos: 34.00%\n",
      "Porcentagem de negativos falsos : 5.00%\n",
      "5\n",
      "0\n",
      "178\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def remover_outliers(lista):\n",
    "    media=sum(lista)/len(lista)\n",
    "    lista2=[]\n",
    "    for i in range(len(lista)):\n",
    "        if abs(lista[i]-media)<(10*media):\n",
    "            lista2.append(lista[i])\n",
    "    return lista2\n",
    "\n",
    "palavra_prob_relevante=[]\n",
    "final_relevante=[1]\n",
    "palavra_prob_nrelevante=[]\n",
    "final_nrelevante=[1]\n",
    "\n",
    "for i in range(len(datatest.Teste)):\n",
    "    palavra_prob_relevante.append([]) \n",
    "    palavra_prob_nrelevante.append([]) \n",
    "    for j in range(len(datatest.Teste[i].split())):\n",
    "        count=lista_rel.count(datatest.Teste[i].split()[j])\n",
    "        count2=lista_nrel.count(datatest.Teste[i].split()[j])\n",
    "           \n",
    "        palavra_prob_relevante[i].append((count+1)/(n_rel+len(lista_total)))\n",
    "        palavra_prob_nrelevante[i].append((count2+1)/(n_nrel+len(lista_total)))      \n",
    "        \n",
    "        #print(\"PALAVRA:{0} FRASE:{1}\".format(datatest.Teste[i].split()[j],i))\n",
    "        #print(result_prob[i][j])\n",
    "        \n",
    "        final_relevante[i]=(final_relevante[i]*palavra_prob_relevante[i][j])\n",
    "        final_nrelevante[i]=(final_nrelevante[i]*palavra_prob_nrelevante[i][j])\n",
    "        \n",
    "    final_relevante.append(1)\n",
    "    final_nrelevante.append(1)       \n",
    "        \n",
    "        \n",
    "falso_positivo=0\n",
    "verdadeiro_positivo=0\n",
    "falso_negativo=0\n",
    "verdadeiro_negativo=0\n",
    "\n",
    "muito_relevante=0 \n",
    "relevante=0\n",
    "neutro=0\n",
    "irrelevante=0\n",
    "muito_irrelevante=0\n",
    "\n",
    "\n",
    "prob_rel=[]\n",
    "prob_nrel=[]\n",
    "\n",
    "for i in range(len(datatest[\"Relevancia\"])):\n",
    "   \n",
    "    if final_relevante[i]>final_nrelevante[i]:\n",
    "        \n",
    "        prob_rel.append(final_relevante[i])\n",
    "        if datatest.Relevancia[i]==\"Relevante\":\n",
    "            \n",
    "            verdadeiro_positivo+=1\n",
    "        else:\n",
    "            falso_positivo+=1        \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        if datatest.Relevancia[i]==\"Não Relevante\":\n",
    "            \n",
    "            prob_nrel.append(final_nrelevante[i])\n",
    "            verdadeiro_negativo+=1\n",
    "            \n",
    "        else:            \n",
    "            falso_negativo+=1\n",
    "               \n",
    "prob_rel=remover_outliers(prob_rel)\n",
    "print(prob_rel)\n",
    "prob_nrel=remover_outliers(prob_nrel)\n",
    "\n",
    "\n",
    "media_relevancia = sum(prob_rel)/len(prob_rel)\n",
    "media_irrelevancia = sum(prob_rel)/len(prob_rel)\n",
    "\n",
    "print(media_relevancia)\n",
    "\n",
    "for i in range(len(prob_rel)):\n",
    "    if final_relevante[i]>media_relevancia:\n",
    "        muito_relevante+=1\n",
    "    else:\n",
    "        if final_relevante[i]>(0.1*media_relevancia):\n",
    "            relevante+=1\n",
    "        else:\n",
    "            neutro+=1\n",
    "\n",
    "for i in range(len(prob_nrel)):\n",
    "    if final_nrelevante[i]>media_irrelevancia:\n",
    "        muito_irrelevante+=1\n",
    "    else:\n",
    "        if final_nrelevante[i]>(0.1*media_irrelevancia):\n",
    "            irrelevante+=1\n",
    "        else:\n",
    "            neutro+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_falso_positivo=falso_positivo/datatest[\"Teste\"].shape[0]\n",
    "p_verdadeiro_positivo=verdadeiro_positivo/datatest[\"Teste\"].shape[0]\n",
    "p_falso_negativo=falso_negativo/datatest[\"Teste\"].shape[0]\n",
    "p_verdadeiro_negativo=verdadeiro_negativo/datatest[\"Teste\"].shape[0]\n",
    "\n",
    "print(\"Porcentagem de positivos verdadeiros :{0:.2f}%\".format(p_verdadeiro_positivo*100))\n",
    "print(\"Porcentagem de negativos verdadeiros: {0:.2f}%\".format(p_verdadeiro_negativo*100))\n",
    "print(\"Porcentagem de positivos falsos: {0:.2f}%\".format(p_falso_positivo*100))\n",
    "print(\"Porcentagem de negativos falsos : {0:.2f}%\".format(p_falso_negativo*100))\n",
    "#print()\n",
    "#print()\n",
    "#\n",
    "#print(\"Porcentagem de muito relevantes :{0:.2f}\".format((muito_relevante/len(datatest[\"Relevancia\"]))*100))\n",
    "#print(\"Porcentagem de relevantes: {0:.2f}\".format((relevante/len(datatest[\"Relevancia\"]))*100))\n",
    "#print(\"Porcentagem de neutros: {0:.2f}%\".format((neutro/len(datatest[\"Relevancia\"]))*100))\n",
    "#print(\"Porcentagem de irrelevantes : {0:.2f}%\".format((irrelevante/len(datatest[\"Relevancia\"]))*100))   \n",
    "#print(\"Porcentagem de muito irrelevantes : {0:.2f}%\".format((muito_irrelevante/len(datatest[\"Relevancia\"]))*100))\n",
    "\n",
    "print(muito_relevante)\n",
    "print(relevante)\n",
    "print(neutro)\n",
    "print(irrelevante)\n",
    "print(muito_irrelevante)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
