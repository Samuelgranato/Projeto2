{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conexão com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que serão utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados é necessário ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: ***@YMartins123***\n",
    "\n",
    "\n",
    "1. Caso ainda não tenha uma: https://twitter.com/signup\n",
    "1. Depois é necessário registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote também:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATENÇÃO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele contém as chaves necessárias para realizar as operações no twitter de forma automática e portanto é equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as operações manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo não precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autenticação do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @fulano\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, não haverá uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Samsung'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documentação do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora você deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem é relevante ou não.<br /> \n",
    "Não se esqueça de colocar um nome para a coluna na célula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu código abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Limpando as mensagens \n",
    "\n",
    "import string\n",
    "import random\n",
    "data=pd.read_excel(\"Samsung.xlsx\")\n",
    "datatest=pd.read_excel(\"Samsung.xlsx\",sheetname=\"Teste\")\n",
    "\n",
    "def sempontuacao(text):  #função que retira todos os sinais(emocotions continuam)\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    return text\n",
    "\n",
    "data[\"Treinamento\"] = data['Treinamento'].apply(sempontuacao)\n",
    "datatest[\"Teste\"] = datatest[\"Teste\"].apply(sempontuacao)\n",
    "data.Treinamento=data.Treinamento.str.replace(\"  \",\" \")#retirando espaços vazios\n",
    "datatest[\"Teste\"] = datatest.Teste.str.replace(\"  \",\" \")\n",
    "data.Treinamento=data.Treinamento.str.replace(\"\\n\",\" \")#retirando espaços vazios\n",
    "datatest[\"Teste\"] = datatest.Teste.str.replace(\"\\n\",\" \")\n",
    "\n",
    "\n",
    "lista_rel = []\n",
    "lista_nrel = []\n",
    "lista_total = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(data[\"Treinamento\"])): #Preenchendo as listas de frases relevantes e irrelevantes\n",
    "    if data[\"Relevancia\"][i]==\"Relevante\":\n",
    "        lista_rel+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "        lista_total+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "    else:\n",
    "        lista_nrel+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "        lista_total+=(list(set(data[\"Treinamento\"][i].split())))\n",
    "        \n",
    "        \n",
    "#lista_rel=  list(set(lista_rel))\n",
    "#lista_nrel = list(set(lista_nrel))\n",
    "\n",
    "lista_total=list(set(lista_total))\n",
    "\n",
    "n_rel = len(lista_rel)\n",
    "n_nrel= len(lista_nrel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivos verdadeiros :5.00%\n",
      "Porcentagem de negativos verdadeiros: 34.00%\n",
      "Porcentagem de positivos falsos: 50.00%\n",
      "Porcentagem de negativos falsos : 11.00%\n",
      "\n",
      "\n",
      "Porcentagem de muito relevantes :13.50%\n",
      "Porcentagem de relevantes: 28.00%\n",
      "Porcentagem de neutros: 24.50%\n",
      "Porcentagem de irrelevantes : 24.50%\n",
      "Porcentagem de muito irrelevantes : 9.50%\n"
     ]
    }
   ],
   "source": [
    "palavra_prob_relevante=[]\n",
    "final_relevante=[1]\n",
    "palavra_prob_nrelevante=[]\n",
    "final_nrelevante=[1]\n",
    "\n",
    "for i in range(len(datatest.Teste)): \n",
    "    palavra_prob_relevante.append([]) \n",
    "    palavra_prob_nrelevante.append([]) \n",
    "    for j in range(len(datatest.Teste[i].split())): \n",
    "        count=lista_rel.count(datatest.Teste[i].split()[j]) #Contagem de ocorrência da palavra de teste com a lista de relevância\n",
    "        count2=lista_nrel.count(datatest.Teste[i].split()[j]) #Contagem de ocorrência da palavra de teste com a lista de irrelevância\n",
    "        \n",
    "        palavra_prob_relevante[i].append((count+1)/(n_rel+len(lista_total))) #Cálculo da probabilidade de relevância por palavra\n",
    "        palavra_prob_nrelevante[i].append((count2+1)/(n_nrel+len(lista_total)))      \n",
    "        \n",
    "        final_relevante[i]=(final_relevante[i]*palavra_prob_relevante[i][j]) #Cálculo da probabilidade por frase\n",
    "        final_nrelevante[i]=(final_nrelevante[i]*palavra_prob_nrelevante[i][j])\n",
    "        \n",
    "    final_relevante.append(1)\n",
    "    final_nrelevante.append(1)       \n",
    "        \n",
    "        \n",
    "falso_positivo=0\n",
    "verdadeiro_positivo=0\n",
    "falso_negativo=0\n",
    "verdadeiro_negativo=0\n",
    "\n",
    "muito_relevante=0 \n",
    "relevante=0\n",
    "neutro=0\n",
    "irrelevante=0\n",
    "muito_irrelevante=0\n",
    "\n",
    "\n",
    "prob_rel=[]\n",
    "prob_nrel=[]\n",
    "\n",
    "for i in range(len(datatest[\"Relevancia\"])):\n",
    "   \n",
    "    if final_relevante[i]<final_nrelevante[i]:\n",
    "        \n",
    "        prob_rel.append(final_relevante[i])\n",
    "        if datatest.Relevancia[i]==\"Relevante\":\n",
    "            \n",
    "            verdadeiro_positivo+=1\n",
    "        else:\n",
    "            falso_positivo+=1        \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        prob_nrel.append(final_nrelevante[i])\n",
    "        if datatest.Relevancia[i]==\"Não Relevante\":            \n",
    "            verdadeiro_negativo+=1\n",
    "            \n",
    "        else:            \n",
    "            falso_negativo+=1\n",
    "prob_rel.sort()\n",
    "prob_nrel.sort()\n",
    "\n",
    "vcentral_relevancia = prob_rel[int(len(prob_rel)/2)]\n",
    "vcentral_irrelevancia =  prob_nrel[int(len(prob_rel)/2)]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(prob_rel)):\n",
    "    if final_relevante[i]>=prob_rel[int(len(prob_rel)*0.75)]:\n",
    "        muito_relevante+=1\n",
    "    else:\n",
    "        if final_relevante[i]>=prob_rel[int(len(prob_rel)*0.25)]:\n",
    "            relevante+=1\n",
    "        else:\n",
    "            neutro+=1\n",
    "\n",
    "for i in range(len(prob_nrel)):\n",
    "    if final_nrelevante[i]>=prob_nrel[int(len(prob_nrel)*0.75)]:\n",
    "        muito_irrelevante+=1\n",
    "    else:\n",
    "        if final_nrelevante[i]>=prob_nrel[int(len(prob_nrel)*0.25)]:\n",
    "            irrelevante+=1\n",
    "        else:\n",
    "            neutro+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_falso_positivo=falso_positivo/datatest[\"Teste\"].shape[0]\n",
    "p_verdadeiro_positivo=verdadeiro_positivo/datatest[\"Teste\"].shape[0]\n",
    "p_falso_negativo=falso_negativo/datatest[\"Teste\"].shape[0]\n",
    "p_verdadeiro_negativo=verdadeiro_negativo/datatest[\"Teste\"].shape[0]\n",
    "\n",
    "print(\"Porcentagem de positivos verdadeiros :{0:.2f}%\".format(p_verdadeiro_positivo*100))\n",
    "print(\"Porcentagem de negativos verdadeiros: {0:.2f}%\".format(p_verdadeiro_negativo*100))\n",
    "print(\"Porcentagem de positivos falsos: {0:.2f}%\".format(p_falso_positivo*100))\n",
    "print(\"Porcentagem de negativos falsos : {0:.2f}%\".format(p_falso_negativo*100))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Porcentagem de muito relevantes :{0:.2f}%\".format((muito_relevante/len(datatest[\"Relevancia\"]))*100))\n",
    "print(\"Porcentagem de relevantes: {0:.2f}%\".format((relevante/len(datatest[\"Relevancia\"]))*100))\n",
    "print(\"Porcentagem de neutros: {0:.2f}%\".format((neutro/len(datatest[\"Relevancia\"]))*100))\n",
    "print(\"Porcentagem de irrelevantes : {0:.2f}%\".format((irrelevante/len(datatest[\"Relevancia\"]))*100))   \n",
    "print(\"Porcentagem de muito irrelevantes : {0:.2f}%\".format((muito_irrelevante/len(datatest[\"Relevancia\"]))*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A partir dos tweets que compuseram a base de treinamento e baseando no classificador Naves-Bayes, montou-se um algoritmo que classifica novas mensagem em Relevantes e Irrelevantes.\n",
    "   Preparando-se uma lista de mensagem para servir de treinamento, foi avaliado tais tweets como relevantes ou irrelevantes para comparar com o resultado apresentado pelo algoritmo. Após a análise final, viu-se que 39% de todas as mensagem foram avaliadas corretamente. Enquanto que 50% foram avaliadas como Relevantes, mas na verdade, eram irrelevantes e 11% foram avaliadas como Irrelevantes, mas eram relevantes.\n",
    "   Uma grande dificuldade de se avaliar a partir de tal classificador é que algumas expressões são compostas com dupla negação e sarcasmo. Pelo fato de o metódo Naves-Bayes analisar se a frase é irrelevante ou relevante palavra por palavra, algumas expressões podem ser classificados de um modo falho.\n",
    " Entretanto, apesar de algumas deficiências, tal projeto deve ser extendido pois ele representa uma análise de como o mercado avalia o seu produto. Dentro do trabalho, existe sempre um ponto positivo ou uma melhoria na marca que é comentada diversas vezes. Isso expõe para a empresa características que devem ser ajustadas para futuras mercadorias a serem lançadas no mercado a fim de melhorar o modo com que o público-alvo avalia a marca.\n",
    "   Para a base de Treinamento não se deve usar o classificador para não existir um vício de avaliações erradas. Isto é, caso novos tweets venham com sarcamo ou algo do genêro, o classificador avaliaria de um modo inexato, fazendo com que o erro se prolongasse para futuras mensagens que também possuiriam sarcamos. Por isso é indicado que a base de treinamento seja avaliada manualmente.\n",
    "   Fora o uso para filtros anti-spam, o classificador Naves-Bayes também pode ser usado em outros tipos de empresas. Por exemplo, uma empresa financeira pode avaliar caso um indivíduo será ou não inadimplente. Basta separar algumas informações dos clientes atuais (renda, estado civil, por exemplo) e usá-las como uma base de treinamento. Após essa ação, tal companhia pode tentar avaliar com mais precisão como será o comportamento de seus consumidores.\n",
    "    Para tentar aprimorar o classificador cada vez mais, um item compatível com tal situação seria um algoritmo capaz de avaliar  o sentimento da mensagem. Com isso, a empresa saíria ganhando duas vezes, uma vez que isso, além de aumentar a precisão de avaliação das mensagens com  sacarmos e dupla negação, ela também mostraria a qualidade com que o mercado avalia o seu produto. Isto é, caso as mensagens Relevantes viessem com um indice de rancor ou infelicidade muito alto, isso significaria que algum ponto dos produtos de tal marca deve ser revisto para que haja uma melhor reação do público-alvo.\n",
    "    Atualmente, para se avaliar sentimento, existem dois tipos de análise: os baseados em aprendizado de máquina e os métodos léxicos. O primeiro depende de algumas bases de dados rotulados para treinar classificadores. Já o segundo depende de uma lista de palavras que são associadas a um sentimento específico.\n",
    "    Por ser uma assunto complexo, segue alguns links que aprofundam mais o metódo de aplicação da análise de sentimento:\n",
    "    *http://homepages.dcc.ufmg.br/~fabricio/download/webmedia-short-course.pdf\n",
    "    *https://s3.amazonaws.com/academia.edu.documents/34632156/Twitter_Sentiment_Classification_using_Distant_Supervision.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&Expires=1505624068&Signature=1GW%2Fy%2Bq7IuTazTHpfXVhoTYPUoY%3D&response-content-disposition=inline%3B%20filename%3DTwitter_Sentiment_Classification_using_D.pdf\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
